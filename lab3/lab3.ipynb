{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dca99df8",
   "metadata": {},
   "source": [
    "## Step 1: Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b87252e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 03:03:37.351531: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78f8b3b",
   "metadata": {},
   "source": [
    "## Step 2: Load the Fashion-MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "769c8fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cc5c39",
   "metadata": {},
   "source": [
    "## Step 3: Take a subset of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a9922fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 28, 28)\n",
      "(1000, 28, 28)\n",
      "(3000,)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "# Initially, take 3,000 samples for training and 1,000 samples for testing.\n",
    "x_dataset = np.concatenate((x_train, x_test), axis=0)\n",
    "y_dataset = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x_dataset, y_dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train3000 = X_train[:3000]\n",
    "Y_train3000 = Y_train[:3000]\n",
    "X_test1000 = X_test[:1000]\n",
    "Y_test1000 = Y_test[:1000]\n",
    "print(X_train3000.shape)\n",
    "print(X_test1000.shape)\n",
    "print(Y_train3000.shape)\n",
    "print(Y_test1000.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eaf20fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 28, 28)\n",
      "(6000,)\n"
     ]
    }
   ],
   "source": [
    "# double the number of training samples from 3,000 to 6,000\n",
    "X_train6000 = X_train[:6000]\n",
    "Y_train6000 = Y_train[:6000]\n",
    "print(X_train6000.shape)\n",
    "print(Y_train6000.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9be4896b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 28, 28)\n",
      "(12000,)\n"
     ]
    }
   ],
   "source": [
    "# then from 6,000 to 12,000, \n",
    "X_train12000 = X_train[:12000]\n",
    "Y_train12000 = Y_train[:12000]\n",
    "print(X_train12000.shape)\n",
    "print(Y_train12000.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6b5bbc",
   "metadata": {},
   "source": [
    "## Step 4: Perform necessary reshaping of the data for the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81527b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 784)\n",
      "(1000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train3000 = X_train3000.reshape(X_train3000.shape[0], -1)\n",
    "X_test1000 = X_test1000.reshape(X_test1000.shape[0], -1)\n",
    "print(X_train3000.shape)\n",
    "print(X_test1000.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e73cdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 784)\n"
     ]
    }
   ],
   "source": [
    "# double the number of training samples from 3,000 to 6,000\n",
    "X_train6000 = X_train6000.reshape(X_train6000.shape[0], -1)\n",
    "print(X_train6000.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "034625c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "# then from 6,000 to 12,000, \n",
    "X_train12000 = X_train12000.reshape(X_train12000.shape[0], -1)\n",
    "print(X_train12000.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f133ffb5",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8899cc",
   "metadata": {},
   "source": [
    "Initially, take 3,000 samples for training and 1,000 samples for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "697c3ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN: 0.778\n",
      "Precision of KNN: 0.7874788219427613\n",
      "Recall of KNN: 0.7773691052384246\n",
      "F1 score of KNN: 0.7750910928717593\n",
      "Confusion matrix of KNN:\n",
      " [[ 84   0   1   2   0   0  11   0   1   0]\n",
      " [  0 111   1   2   1   0   0   0   0   0]\n",
      " [  6   0  76   0  20   1   8   0   0   0]\n",
      " [ 13   4   5  64   6   0   1   0   1   0]\n",
      " [  3   0  20   1  62   0  15   0   0   0]\n",
      " [  2   0   0   0   0  74   0  17   0  12]\n",
      " [ 22   0  14   1  10   0  45   0   0   0]\n",
      " [  0   0   0   0   0   0   0  74   0   3]\n",
      " [  2   0   3   0   0   1   2   2  96   0]\n",
      " [  1   0   1   0   0   0   0   6   0  92]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Step 5: Initialise the classifier model\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "# Step 6: Fit the model to the training data\n",
    "knn_classifier.fit(X_train3000, Y_train3000)\n",
    "# Step 7: Use the trained/fitted model to evaluate the testing data\n",
    "knn_pred = knn_classifier.predict(X_test1000)\n",
    "# Step 8: Report the performance of each classifier\n",
    "accuracy_knn = metrics.accuracy_score(Y_test1000, knn_pred)\n",
    "precision_knn = metrics.precision_score(Y_test1000, knn_pred, average='macro')\n",
    "recall_knn = metrics.recall_score(Y_test1000, knn_pred, average = 'macro')\n",
    "f1_score_knn = metrics.f1_score(Y_test1000, knn_pred, average = 'macro')\n",
    "confusion_matrix_knn = metrics.confusion_matrix(Y_test1000, knn_pred)\n",
    "\n",
    "print(f'Accuracy of KNN: {accuracy_knn}')\n",
    "print(f'Precision of KNN: {precision_knn}')\n",
    "print(f'Recall of KNN: {recall_knn}')\n",
    "print(f'F1 score of KNN: {f1_score_knn}')\n",
    "print(f'Confusion matrix of KNN:\\n {confusion_matrix_knn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c68d8c",
   "metadata": {},
   "source": [
    "6,000 samples for training and 1,000 samples for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adcbf00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN: 0.81\n",
      "Precision of KNN: 0.8163858384302187\n",
      "Recall of KNN: 0.8094840713615868\n",
      "F1 score of KNN: 0.8080998363570335\n",
      "Confusion matrix of KNN:\n",
      " [[ 86   0   1   2   0   0   9   0   1   0]\n",
      " [  2 110   1   1   0   0   1   0   0   0]\n",
      " [  6   0  81   0  16   1   7   0   0   0]\n",
      " [  9   2   5  74   1   0   2   0   1   0]\n",
      " [  1   0  18   0  67   0  15   0   0   0]\n",
      " [  1   0   0   0   0  76   0  13   0  15]\n",
      " [ 20   0  14   0   8   0  50   0   0   0]\n",
      " [  0   0   0   0   0   2   0  73   0   2]\n",
      " [  2   0   0   1   1   0   2   1  99   0]\n",
      " [  0   0   1   0   0   0   1   4   0  94]]\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Fit the model to the training data\n",
    "knn_classifier.fit(X_train6000, Y_train6000)\n",
    "# Step 7: Use the trained/fitted model to evaluate the testing data\n",
    "knn_pred = knn_classifier.predict(X_test1000)\n",
    "# Step 8: Report the performance of each classifier\n",
    "accuracy_knn = metrics.accuracy_score(Y_test1000, knn_pred)\n",
    "precision_knn = metrics.precision_score(Y_test1000, knn_pred, average='macro')\n",
    "recall_knn = metrics.recall_score(Y_test1000, knn_pred, average = 'macro')\n",
    "f1_score_knn = metrics.f1_score(Y_test1000, knn_pred, average = 'macro')\n",
    "confusion_matrix_knn = metrics.confusion_matrix(Y_test1000, knn_pred)\n",
    "\n",
    "print(f'Accuracy of KNN: {accuracy_knn}')\n",
    "print(f'Precision of KNN: {precision_knn}')\n",
    "print(f'Recall of KNN: {recall_knn}')\n",
    "print(f'F1 score of KNN: {f1_score_knn}')\n",
    "print(f'Confusion matrix of KNN:\\n {confusion_matrix_knn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a21fa4",
   "metadata": {},
   "source": [
    "12,000 samples for training and 1,000 samples for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76a089e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN: 0.816\n",
      "Precision of KNN: 0.8196580092812894\n",
      "Recall of KNN: 0.8147083841235665\n",
      "F1 score of KNN: 0.8129048889643513\n",
      "Confusion matrix of KNN:\n",
      " [[ 81   1   1   2   0   0  13   0   1   0]\n",
      " [  0 111   1   1   1   0   1   0   0   0]\n",
      " [  4   0  87   0   9   0  10   1   0   0]\n",
      " [  9   2   3  74   3   0   2   0   1   0]\n",
      " [  1   0  16   2  70   0  12   0   0   0]\n",
      " [  0   0   0   0   0  78   0  14   0  13]\n",
      " [ 19   0  13   0  12   0  48   0   0   0]\n",
      " [  0   0   0   0   0   0   0  74   0   3]\n",
      " [  1   1   0   0   1   0   2   1  99   1]\n",
      " [  0   0   1   1   0   0   0   4   0  94]]\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Fit the model to the training data\n",
    "knn_classifier.fit(X_train12000, Y_train12000)\n",
    "# Step 7: Use the trained/fitted model to evaluate the testing data\n",
    "knn_pred = knn_classifier.predict(X_test1000)\n",
    "# Step 8: Report the performance of each classifier\n",
    "accuracy_knn = metrics.accuracy_score(Y_test1000, knn_pred)\n",
    "precision_knn = metrics.precision_score(Y_test1000, knn_pred, average='macro')\n",
    "recall_knn = metrics.recall_score(Y_test1000, knn_pred, average = 'macro')\n",
    "f1_score_knn = metrics.f1_score(Y_test1000, knn_pred, average = 'macro')\n",
    "confusion_matrix_knn = metrics.confusion_matrix(Y_test1000, knn_pred)\n",
    "\n",
    "print(f'Accuracy of KNN: {accuracy_knn}')\n",
    "print(f'Precision of KNN: {precision_knn}')\n",
    "print(f'Recall of KNN: {recall_knn}')\n",
    "print(f'F1 score of KNN: {f1_score_knn}')\n",
    "print(f'Confusion matrix of KNN:\\n {confusion_matrix_knn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68facd2b",
   "metadata": {},
   "source": [
    "### Our result is less accurate than that on the paper. The knn of the paper is about 0.85 and 0.95, but I only get about 0.78, 0.81, 0.82. This may be because we only set three neighbors here. The number is too small for this dataset, and maybe n = 5 or 9 is better. Also, I find that we do more training sample, get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b0d215",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0a611d",
   "metadata": {},
   "source": [
    "Initially, take 3,000 samples for training and 1,000 samples for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3a1d5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SGD: 0.781\n",
      "Precision of SGD: 0.7822483110826501\n",
      "Recall of SGD: 0.7795498982661585\n",
      "F1 score of SGD: 0.7742511149236707\n",
      "Confusion matrix of SGD:\n",
      " [[ 80   0   0   5   1   0  10   0   3   0]\n",
      " [  1 111   0   2   0   0   1   0   0   0]\n",
      " [  6   0  58   2  28   1  13   0   3   0]\n",
      " [  7   0   3  77   4   0   2   0   1   0]\n",
      " [  2   1   6   3  81   0   8   0   0   0]\n",
      " [  0   0   0   0   2  80   0   8   7   8]\n",
      " [ 17   0   8   4  26   0  34   0   3   0]\n",
      " [  0   0   0   0   0   4   0  68   1   4]\n",
      " [  3   0   0   0   1   1   1   1  99   0]\n",
      " [  0   0   0   0   0   3   1   1   2  93]]\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Initialise the classifier model\n",
    "sgd_classifier = SGDClassifier(max_iter=250)\n",
    "# Step 6: Fit the model to the training data\n",
    "sgd_classifier.fit(X_train3000, Y_train3000)\n",
    "# Step 7: Use the trained/fitted model to evaluate the testing data\n",
    "sgd_pred = sgd_classifier.predict(X_test1000)\n",
    "# Step 8: Report the performance of each classifier\n",
    "accuracy_sgd = metrics.accuracy_score(Y_test1000, sgd_pred)\n",
    "precision_sgd = metrics.precision_score(Y_test1000, sgd_pred, average='macro')\n",
    "recall_sgd = metrics.recall_score(Y_test1000, sgd_pred, average = 'macro')\n",
    "f1_score_sgd = metrics.f1_score(Y_test1000, sgd_pred, average = 'macro')\n",
    "confusion_matrix_sgd = metrics.confusion_matrix(Y_test1000, sgd_pred)\n",
    "\n",
    "print(f'Accuracy of SGD: {accuracy_sgd}')\n",
    "print(f'Precision of SGD: {precision_sgd}')\n",
    "print(f'Recall of SGD: {recall_sgd}')\n",
    "print(f'F1 score of SGD: {f1_score_sgd}')\n",
    "print(f'Confusion matrix of SGD:\\n {confusion_matrix_sgd}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18acb388",
   "metadata": {},
   "source": [
    "6,000 samples for training and 1,000 samples for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ca43088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SGD: 0.762\n",
      "Precision of SGD: 0.7919274985601015\n",
      "Recall of SGD: 0.7598601731733755\n",
      "F1 score of SGD: 0.7570723063163154\n",
      "Confusion matrix of SGD:\n",
      " [[ 86   0   0   2   2   0   7   0   2   0]\n",
      " [  4 107   1   1   2   0   0   0   0   0]\n",
      " [  6   0  50   0  49   1   5   0   0   0]\n",
      " [ 10   0   2  67  14   0   1   0   0   0]\n",
      " [  2   0   6   0  88   0   5   0   0   0]\n",
      " [  1   0   0   0   2  88   0   5   2   7]\n",
      " [ 14   1   9   1  46   0  21   0   0   0]\n",
      " [  0   0   0   0   0   3   0  67   1   6]\n",
      " [  2   0   0   0   6   1   6   0  91   0]\n",
      " [  0   0   0   0   0   2   0   1   0  97]]\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Fit the model to the training data\n",
    "sgd_classifier.fit(X_train6000, Y_train6000)\n",
    "# Step 7: Use the trained/fitted model to evaluate the testing data\n",
    "sgd_pred = sgd_classifier.predict(X_test1000)\n",
    "# Step 8: Report the performance of each classifier\n",
    "accuracy_sgd = metrics.accuracy_score(Y_test1000, sgd_pred)\n",
    "precision_sgd = metrics.precision_score(Y_test1000, sgd_pred, average='macro')\n",
    "recall_sgd = metrics.recall_score(Y_test1000, sgd_pred, average = 'macro')\n",
    "f1_score_sgd = metrics.f1_score(Y_test1000, sgd_pred, average = 'macro')\n",
    "confusion_matrix_sgd = metrics.confusion_matrix(Y_test1000, sgd_pred)\n",
    "\n",
    "print(f'Accuracy of SGD: {accuracy_sgd}')\n",
    "print(f'Precision of SGD: {precision_sgd}')\n",
    "print(f'Recall of SGD: {recall_sgd}')\n",
    "print(f'F1 score of SGD: {f1_score_sgd}')\n",
    "print(f'Confusion matrix of SGD:\\n {confusion_matrix_sgd}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3047863f",
   "metadata": {},
   "source": [
    "12,000 samples for training and 1,000 samples for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbc833e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SGD: 0.797\n",
      "Precision of SGD: 0.7989197540163577\n",
      "Recall of SGD: 0.7954874834828334\n",
      "F1 score of SGD: 0.7958031207259427\n",
      "Confusion matrix of SGD:\n",
      " [[ 68   0   2   5   3   0  17   0   4   0]\n",
      " [  2 109   0   1   2   0   1   0   0   0]\n",
      " [  2   0  74   1  20   1  12   0   1   0]\n",
      " [  2   0   2  81   7   0   2   0   0   0]\n",
      " [  0   0  15   2  73   1  10   0   0   0]\n",
      " [  0   0   0   0   0  86   1   7   7   4]\n",
      " [  9   0  14   4  12   0  50   0   3   0]\n",
      " [  0   0   0   0   0   3   0  68   1   5]\n",
      " [  1   0   1   0   0   1   3   0 100   0]\n",
      " [  0   0   0   0   0   5   0   6   1  88]]\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Fit the model to the training data\n",
    "sgd_classifier.fit(X_train12000, Y_train12000)\n",
    "# Step 7: Use the trained/fitted model to evaluate the testing data\n",
    "sgd_pred = sgd_classifier.predict(X_test1000)\n",
    "# Step 8: Report the performance of each classifier\n",
    "accuracy_sgd = metrics.accuracy_score(Y_test1000, sgd_pred)\n",
    "precision_sgd = metrics.precision_score(Y_test1000, sgd_pred, average='macro')\n",
    "recall_sgd = metrics.recall_score(Y_test1000, sgd_pred, average = 'macro')\n",
    "f1_score_sgd = metrics.f1_score(Y_test1000, sgd_pred, average = 'macro')\n",
    "confusion_matrix_sgd = metrics.confusion_matrix(Y_test1000, sgd_pred)\n",
    "\n",
    "print(f'Accuracy of SGD: {accuracy_sgd}')\n",
    "print(f'Precision of SGD: {precision_sgd}')\n",
    "print(f'Recall of SGD: {recall_sgd}')\n",
    "print(f'F1 score of SGD: {f1_score_sgd}')\n",
    "print(f'Confusion matrix of SGD:\\n {confusion_matrix_sgd}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b442bde",
   "metadata": {},
   "source": [
    "### Our results are worse than those on paper. The accuracy of this paper is close to 0.819 in the fashion industry, but I only get about 0.78(3000 training),0.76(6000 training). Maybe because we only use max_Iter is set to 250 to limit the maximum number of algorithm iterations. Also the training times of our model are far less than those of the model in this paper, which may lead to insufficient fitting and reduced accuracy. So when we use 12000 samples training, we got very close to paper's accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba958a2b",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38d220d",
   "metadata": {},
   "source": [
    "Initially, take 3,000 samples for training and 1,000 samples for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "455fcdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SGD: 0.723\n",
      "Precision of SGD: 0.723770031801464\n",
      "Recall of SGD: 0.7204559909585355\n",
      "F1 score of SGD: 0.7212921159148163\n",
      "Confusion matrix of SGD:\n",
      " [[ 61   0   8   3   1   0  25   0   1   0]\n",
      " [  1 107   0   4   1   0   2   0   0   0]\n",
      " [  7   2  63   0  21   2  16   0   0   0]\n",
      " [  5   6   2  69   7   0   4   0   1   0]\n",
      " [  2   1  16   8  53   1  17   0   2   1]\n",
      " [  0   0   0   0   0  86   0  10   4   5]\n",
      " [ 14   1  14   4  11   0  46   0   2   0]\n",
      " [  0   0   0   0   0   7   0  62   1   7]\n",
      " [  1   2   4   1   0   0   2   1  93   2]\n",
      " [  0   0   2   0   0   6   0   9   0  83]]\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Initialise the classifier model\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "# Step 6: Fit the model to the training data\n",
    "dt_classifier.fit(X_train3000, Y_train3000)\n",
    "# Step 7: Use the trained/fitted model to evaluate the testing data\n",
    "dt_pred = dt_classifier.predict(X_test1000)\n",
    "# Step 8: Report the performance of each classifier\n",
    "accuracy_dt = metrics.accuracy_score(Y_test1000, dt_pred)\n",
    "precision_dt = metrics.precision_score(Y_test1000, dt_pred, average='macro')\n",
    "recall_dt = metrics.recall_score(Y_test1000, dt_pred, average = 'macro')\n",
    "f1_score_dt = metrics.f1_score(Y_test1000, dt_pred, average = 'macro')\n",
    "confusion_matrix_dt = metrics.confusion_matrix(Y_test1000, dt_pred)\n",
    "\n",
    "print(f'Accuracy of SGD: {accuracy_dt}')\n",
    "print(f'Precision of SGD: {precision_dt}')\n",
    "print(f'Recall of SGD: {recall_dt}')\n",
    "print(f'F1 score of SGD: {f1_score_dt}')\n",
    "print(f'Confusion matrix of SGD:\\n {confusion_matrix_dt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3342fa5",
   "metadata": {},
   "source": [
    "6,000 samples for training and 1,000 samples for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56dd03dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SGD: 0.738\n",
      "Precision of SGD: 0.7378112331168756\n",
      "Recall of SGD: 0.7371170216109972\n",
      "F1 score of SGD: 0.736686816025544\n",
      "Confusion matrix of SGD:\n",
      " [[ 70   2   4   7   2   0  10   0   4   0]\n",
      " [  1 105   0   3   1   1   4   0   0   0]\n",
      " [  2   1  63   2  16   2  21   0   2   2]\n",
      " [  7   6   3  69   4   1   4   0   0   0]\n",
      " [  2   2  18   8  57   0  12   0   2   0]\n",
      " [  0   1   0   0   0  88   0   7   4   5]\n",
      " [ 10   0   8   4  16   1  51   0   2   0]\n",
      " [  0   0   0   0   0   7   0  65   0   5]\n",
      " [  3   0   3   1   1   1   4   1  91   1]\n",
      " [  0   0   0   3   1   9   1   7   0  79]]\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Fit the model to the training data\n",
    "dt_classifier.fit(X_train6000, Y_train6000)\n",
    "# Step 7: Use the trained/fitted model to evaluate the testing data\n",
    "dt_pred = dt_classifier.predict(X_test1000)\n",
    "# Step 8: Report the performance of each classifier\n",
    "accuracy_dt = metrics.accuracy_score(Y_test1000, dt_pred)\n",
    "precision_dt = metrics.precision_score(Y_test1000, dt_pred, average='macro')\n",
    "recall_dt = metrics.recall_score(Y_test1000, dt_pred, average = 'macro')\n",
    "f1_score_dt = metrics.f1_score(Y_test1000, dt_pred, average = 'macro')\n",
    "confusion_matrix_dt = metrics.confusion_matrix(Y_test1000, dt_pred)\n",
    "\n",
    "print(f'Accuracy of SGD: {accuracy_dt}')\n",
    "print(f'Precision of SGD: {precision_dt}')\n",
    "print(f'Recall of SGD: {recall_dt}')\n",
    "print(f'F1 score of SGD: {f1_score_dt}')\n",
    "print(f'Confusion matrix of SGD:\\n {confusion_matrix_dt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56084e6d",
   "metadata": {},
   "source": [
    "12,000 samples for training and 1,000 samples for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ae8c0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SGD: 0.744\n",
      "Precision of SGD: 0.7519454637909927\n",
      "Recall of SGD: 0.7405433119928151\n",
      "F1 score of SGD: 0.744420032856023\n",
      "Confusion matrix of SGD:\n",
      " [[ 67   0   1   3   4   0  23   0   1   0]\n",
      " [  1 107   0   6   1   0   0   0   0   0]\n",
      " [  4   2  63   2  19   1  19   0   1   0]\n",
      " [  5   4   4  66   9   1   4   0   1   0]\n",
      " [  1   1  18   8  59   0  13   0   1   0]\n",
      " [  0   0   0   0   0  96   0   2   2   5]\n",
      " [ 11   0   8   6  21   1  44   0   1   0]\n",
      " [  1   0   0   0   0  11   0  61   0   4]\n",
      " [  4   1   1   0   0   1   8   0  89   2]\n",
      " [  0   0   0   0   0   3   1   4   0  92]]\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Fit the model to the training data\n",
    "dt_classifier.fit(X_train12000, Y_train12000)\n",
    "# Step 7: Use the trained/fitted model to evaluate the testing data\n",
    "dt_pred = dt_classifier.predict(X_test1000)\n",
    "# Step 8: Report the performance of each classifier\n",
    "accuracy_dt = metrics.accuracy_score(Y_test1000, dt_pred)\n",
    "precision_dt = metrics.precision_score(Y_test1000, dt_pred, average='macro')\n",
    "recall_dt = metrics.recall_score(Y_test1000, dt_pred, average = 'macro')\n",
    "f1_score_dt = metrics.f1_score(Y_test1000, dt_pred, average = 'macro')\n",
    "confusion_matrix_dt = metrics.confusion_matrix(Y_test1000, dt_pred)\n",
    "\n",
    "print(f'Accuracy of SGD: {accuracy_dt}')\n",
    "print(f'Precision of SGD: {precision_dt}')\n",
    "print(f'Recall of SGD: {recall_dt}')\n",
    "print(f'F1 score of SGD: {f1_score_dt}')\n",
    "print(f'Confusion matrix of SGD:\\n {confusion_matrix_dt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c762ed",
   "metadata": {},
   "source": [
    "### We found that the more sample training data, the better accuracy we got. However, our results are less accuracy than its on paper. The accuracy by DT classifier in paper is between 0.78 and 0.79. But our accuracy is  0.723 (3000 training), 0.738(6000 training), 0.744(12000 training). The reason may be that the subset we get from the whole dataset may not have the same data distribution as the whole dataset used in the paper, which affects the accuracy of the training classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
